{
  "hash": "61f60d912ce114e1546e0b3528bb1e44",
  "result": {
    "markdown": "---\ntitle: Visualizing Inference\nsubtitle: Lecture 14\ntitle-slide-attributes:\n  data-background-image: ../vizdata-bg.png\n  data-background-size: 800px, cover\n  data-slide-number: none\nformat: revealjs\nhighlight-style: a11y\nexecute:\n  code-link: true\n  warning: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n# Warm up\n\n## Announcements\n\n-   Project 1 feedback is posted\n\n-   Scores for all assignments so far will be on D2L soon\n\n-   Project 2 groups will be announced by the end of this week \n\n-   Take a note of the deadlines for the rest of the semester\n\n# Project 2\n\n## Project 2 - potential directions {.smaller}\n\n::: incremental\n-   Present and visualize a technical topic in statistics or mathematics, e.g., Gradient descent, quadrature, autoregressive (AR) models, etc.\n\n-   Build a Shiny app that that has an Instagram-like user interface for applying filters, except not filters but themes for ggplots.\n\n-   Create an R package that provides functionality for a set of ggplot2 themes and/or color palettes.\n\n-   Build a generative art system.\n\n-   Do a deep dive into accessibility for data visualization and build a lesson plan for creating accessible visualizations with ggplot2, R Markdown, and generally within the R ecosystem.\n\n-   Create an interactive and/or animated spatio-temporal visualization on a topic of interest to you, e.g., redistricting, COVID-19, voter suppression, etc.\n\n-   Recreate art pieces with ggplot2.\n\n-   Make a data visualization telling a story and convert it to an illustration, presenting both the computational and artistic piece side by side.\n\n-   Build a dashboard.\n\n-   Or... Visualize a (non-TidyTuesday) dataset, answering a research question of interest to you.\n:::\n\n## Project 2 - all the details\n\n::: large\n<https://datavizaz.org/project/project-2.html>\n:::\n\n<br>\n\n::: callout-tip\nBrainstorm a bunch of ideas and discard them until you settle on a topic that everyone in the team is happy with and feels like a good choice for showcasing what you've learned in the class and how you can use that to learn something new and implement for your project.\n:::\n\n## Project 2 - inspiration\n\n-   animatedata - [Formula 1 racing](https://charts.animateddata.co.uk/f1/)\n\n-   Nicole Rennie - [Life Expectancy](https://github.com/nrennie/Significance/tree/main/Were_not_getting_any_younger_Or_should_that_be_older)\n\n-   Nicole Rennie - [Generative Art](https://github.com/nrennie/nrennie_aRt)\n\n## Setup\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(nullabor)\nlibrary(skimr)\n\n# set default theme for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\nupdate_geom_defaults(\"point\", list(size = 2)) # 2 for full width, 2.5 for half width\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8, fig.asp = 0.618, fig.retina = 3, dpi = 300, out.width = \"60%\"\n)\n\n# dplyr print min and max\noptions(dplyr.print_max = 10, dplyr.print_min = 10)\n```\n:::\n\n\n\n---\n\nclass: middle, inverse\n\n# Now you see me, now you don't\n\n---\n\n.task[\nOne of the pictures is a photograph of a painting by Piet Mondrian while the other is a photograph of a drawing made by an IBM 7094 digital computer. Which of the two do you think was done by the computer?\n]\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/mondrian-computer.png){fig-align='center' width=75%}\n:::\n:::\n\n\n.small[\nA. M. Noll, \"Human or machine: A subjective comparison of\npiet mondrian's \"composition with lines\" (1917) and a computer-\ngenerated picture,\" The Psychological Record, vol. 16, pp. 1–10,\n1966.\n]\n\n---\n\n## Aside: Who is Piet Mondrian?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/mondrian-composition-red-blue-yellow.jpg){fig-align='center' width=50%}\n:::\n:::\n\n\n---\n\n.task[\nWhat is **apophenia**?\n]\n\n--\n\n.pull-left[\nThe tendency to perceive a connection or meaningful pattern between unrelated or random things \n]\n.pull-right[\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/cloud-witch.jpg){width=80%}\n:::\n:::\n\n]\n\n---\n\n## Visualization, statistical inference, visual inference\n\n- **Visualization** provides tools to uncover new relationships, tools of curiosity, and much of visualization research focuses on making the chance of finding relationships as high as possible\n\n--\n- **Statistical inference** provides tools to check whether a relationship really exists (tools of skepticism) and most statistics research focuses on making sure to minimize the chance of finding a relationship that does not exist\n  - Testing: *Is there a difference?*\n  - Estimation: *How big is the difference?*\n\n--\n- **Visual inference** bridges these two conflicting drives to provide\na tool for skepticism that can be applied in a curiosity-driven context\n  - Testing: *Is what we see really there, i.e., is what we see in a plot of the sample an accurate reflection of the entire population?*\n\n---\n\n## Hypothesis testing as a court trial\n\n- **Null hypothesis**, $H_0$: Defendant is innocent\n\n- **Alternative hypothesis**, $H_A$: Defendant is guilty\n\n--\n\n- **Present the evidence:** Collect data\n\n--\n\n- **Judge the evidence:** \"Could these data plausibly have happened by chance if the null hypothesis were true?\"\n    * Yes: Fail to reject $H_0$\n    * No: Reject $H_0$\n    \n---\n\n## Hypothesis testing framework\n\n- Start with a null hypothesis, $H_0$, that represents the status quo\n\n- Set an alternative hypothesis, $H_A$, that represents the research question, i.e. what we’re testing for\n\n- Conduct a hypothesis test under the assumption that the null hypothesis is true and calculate a **p-value** (probability of observed or more extreme outcome given that the null hypothesis is true)\n    - if the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\n    - if they do, then reject the null hypothesis in favor of the alternative\n\n---\n\n## Potential errors\n\n- Type 1 error (false negative): Acquit / reject $H_0$ when you shouldn't\n\n- Type 2 error (false positive): Falsely convict an innocent / fail to reject $H_0$ when you shouldn't\n\n- Costs of these errors vary based on the severity of the consequences\n\n---\n\n## Statistical vs. visual inference\n\n.pull-left[\nStatistical\n\n- Test statistic\n- p-value compared to significance level\n]\n.pull-right[\nVisual\n\n- Plot of the data\n- Humans' picking an \"innocent\" out of a series of **null plot**s\n]\n\n---\n\nclass: middle, inverse\n\n# Visual inference with a lineup\n\n---\n\n## The lineup protocol\n\n- Plot of the real data is randomly embedded amongst a set of null plots\n\n- Matrix of plots is known as a **lineup**\n\n- Null plots are generated by a method consistent with the null hypothesis\n\n- The lineup is shown to an observer. If the observer can pick the real data as different from the others, this puts weight on the statistical significance of the structure in the plot.\n\n- The `lineup()` function from the [**nullabor**](http://dicook.github.io/nullabor/) package returns a set of generated null datasets and the real data embedded randomly among these null datasets\n\n---\n\n## Using `nullabor::lineup()`\n\n- Generating null plots:\n  - Option 1: Provide a method of generation and let the `lineup()` function generate them\n  - Option 2: Generating the null datasets yourself and pass them to the `lineup()` function\n\n- Position of the real dataset is hidden by default\n  - Decrypt to find out which plot is the real dataset\n\n---\n\n## Will the real `mtcars` please stand up?\n\n.panelset.sideways[\n.panel[.panel-name[Plot]\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=100%}\n:::\n:::\n\n]\n.panel[.panel-name[Vote]\n\n<iframe src=\"https://app.sli.do/event/rxg9buzy\" height=\"100%\" width=\"100%\" frameBorder=\"0\" style=\"min-height: 560px;\" title=\"Slido\"></iframe>\n\n]\n]\n\n---\n\n## The making of the lineup I\n\nStep 1. Permute the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20211029)\nmtcars_permuted_lineup <- lineup(null_permute(\"mpg\"), mtcars)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ndecrypt(\"clZx bKhK oL 3OHohoOL 0Y\")\n```\n:::\n:::\n\n\n---\n\n## The making of the lineup II\n\nStep 2. Peek at the permuted data\n\n.panelset[\n.panel[.panel-name[Permuted data]\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(mtcars_permuted_lineup)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      mpg cyl disp  hp drat    wt  qsec vs am gear carb .sample\n...1 10.4   6  160 110 3.90 2.620 16.46  0  1    4    4       1\n...2 21.4   6  160 110 3.90 2.875 17.02  0  1    4    4       1\n...3 14.7   4  108  93 3.85 2.320 18.61  1  1    4    1       1\n...4 15.5   6  258 110 3.08 3.215 19.44  1  0    3    1       1\n...5 30.4   8  360 175 3.15 3.440 17.02  0  0    3    2       1\n...6 15.0   6  225 105 2.76 3.460 20.22  1  0    3    1       1\n```\n:::\n:::\n\n]\n.panel[.panel-name[Permutations]\n`n = 20` by default\n.small[\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars_permuted_lineup %>%\n  count(.sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   .sample  n\n1        1 32\n2        2 32\n3        3 32\n4        4 32\n5        5 32\n6        6 32\n7        7 32\n8        8 32\n9        9 32\n10      10 32\n11      11 32\n12      12 32\n13      13 32\n14      14 32\n15      15 32\n16      16 32\n17      17 32\n18      18 32\n19      19 32\n20      20 32\n```\n:::\n:::\n\n]\n]\n]\n\n---\n\n## The making of the lineup III\n\nStep 3. Plot the permutations\n\n.panelset.sideways[\n\n::: {.cell panelset='[\"Code\",\"Plot\"]'}\n\n```{.r .cell-code}\nggplot(data = mtcars_permuted_lineup, aes(x = mpg, y = wt)) +\n  geom_point() +\n  facet_wrap(~ .sample)\n```\n\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/unnamed-chunk-9-1.png){width=100%}\n:::\n:::\n\n]\n\n---\n\n## Decrypt the lineup\n\n\n::: {.cell hash='17-visual-inference_cache/revealjs/unnamed-chunk-10_404cbd28b156c279ad4f18c55a0fd6be'}\n\n```{.r .cell-code}\ndecrypt(\"sD0f gCdC En JP2EdEPn 8j\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in decrypt(\"sD0f gCdC En JP2EdEPn 8j\"): NAs introduced by coercion\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PO2j w939 4F SEm434EF  NA\"\n```\n:::\n:::\n\n\n---\n\nclass: middle, inverse\n\n# Visual inference with a Rorschach\n\n---\n\n## The Rorschach protocol\n\n- The **Rorschach** protocol is used to calibrate the eyes for variation due to sampling\n\n--\n- Plots generated corresponds to the null datasets, data that is consistent with a null hypothesis\n\n--\n- `rorschach()` function returns a set of null plots which are shown to observers to calibrate their eyes with variation\n\n---\n\n## Using `nullabor::rorschach()`\n\n- Generating null plots: Provide a `method` of generation and let the `rorschach()` function generate them\n\n- Provide the `true` data set\n\n- Set `n`, total number of samples to generate (`n = 20` by default)\n\n- Set `p`, probability of including true data with null data (`p = 0` by default)\n\n---\n\n## Train your eyes to spot the real `mtcars`\n\n.panelset.sideways[\n.panel[.panel-name[Plot]\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=100%}\n:::\n:::\n\n]\n.panel[.panel-name[Vote]\n\n<iframe src=\"https://app.sli.do/event/rxg9buzy\" height=\"100%\" width=\"100%\" frameBorder=\"0\" style=\"min-height: 560px;\" title=\"Slido\"></iframe>\n\n]\n]\n\n---\n\n## The making of the rorschach I\n\nStep 1. Permute the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20211029)\nmtcars_permuted_rorschach <- rorschach(null_permute(\"mpg\"), mtcars)\n```\n:::\n\n\n---\n\n## The making of the rorschach II\n\nStep 2. Peek at the permuted data\n\n.panelset[\n.panel[.panel-name[Permuted data]\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(mtcars_permuted_rorschach)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   mpg cyl disp  hp drat    wt  qsec vs am gear carb .sample\n1 10.4   6  160 110 3.90 2.620 16.46  0  1    4    4       1\n2 21.4   6  160 110 3.90 2.875 17.02  0  1    4    4       1\n3 14.7   4  108  93 3.85 2.320 18.61  1  1    4    1       1\n4 15.5   6  258 110 3.08 3.215 19.44  1  0    3    1       1\n5 30.4   8  360 175 3.15 3.440 17.02  0  0    3    2       1\n6 15.0   6  225 105 2.76 3.460 20.22  1  0    3    1       1\n```\n:::\n:::\n\n]\n.panel[.panel-name[Permutations]\n`n = 20` by default\n.small[\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcars_permuted_rorschach %>%\n  count(.sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   .sample  n\n1        1 32\n2        2 32\n3        3 32\n4        4 32\n5        5 32\n6        6 32\n7        7 32\n8        8 32\n9        9 32\n10      10 32\n11      11 32\n12      12 32\n13      13 32\n14      14 32\n15      15 32\n16      16 32\n17      17 32\n18      18 32\n19      19 32\n20      20 32\n```\n:::\n:::\n\n]\n]\n]\n\n---\n\n## The making of the rorschach III\n\nStep 3. Plot the permutations\n\n.panelset.sideways[\n\n::: {.cell panelset='[\"Code\",\"Plot\"]'}\n\n```{.r .cell-code}\nggplot(data = mtcars_permuted_rorschach, aes(x = mpg, y = wt)) +\n  geom_point() +\n  facet_wrap(~ .sample)\n```\n\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/unnamed-chunk-15-1.png){width=100%}\n:::\n:::\n\n]\n\n---\n\n## Decrypt the rorschach\n\n- In this particular case there's nothing to decrypt since `p` (probability of including true data with null data) is set to 0\n\n- If `p` is higher than 0, and the true null is included, you get the decryption key\n\n\n::: {.cell hash='17-visual-inference_cache/revealjs/decrypt-mtcars-rorschach-p05_4253b027b0cd3a1bb7715d1e2b8c777a'}\n\n```{.r .cell-code}\nset.seed(12345)\nmtcars_permuted_rorschach <- rorschach(null_permute(\"mpg\"), mtcars, p = 0.5)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nclZx bKhK oL 3OHohoOL 0Q\n```\n:::\n\n```{.r .cell-code}\ndecrypt(\"sD0f gCdC En JP2EdEPn 8Y\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in decrypt(\"sD0f gCdC En JP2EdEPn 8Y\"): NAs introduced by coercion\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PO2j w939 4F SEm434EF  NA\"\n```\n:::\n:::\n\n\n---\n\nclass: middle, inverse\n\n# Generating the null data\n\n---\n\n## Generating the null data\n\n- By permuting a variable (what we've done so far with `mtcars`)\n\n--\n- With a specific distribution\n\n--\n- With null residuals from a model\n\n--\n- With null data outside of **nullabor** (we won't get into this, but see [here](http://dicook.github.io/nullabor/articles/nullabor.html#generate-null-data-outside-of-nullabor) for more)\n\n---\n\n## Generate null data with a specific distribution\n\n- The `null_dist()` function takes as input a variable name of the data and a particular distribution\n\n- This variable in the data is substituted by random generations of the particular distribution\n\n- The different distributions include beta, cauchy, chi-squared, exponential, f, gamma, geometric, log-normal, lognormal, logistic, negative binomial, normal, poisson, t, and weibull\n\n- Parameters of the distributions are estimated from the given data (default) or can be provided as a list\n\n- `null_dist()` returns a function that generates a null data set given the data \n\n---\n\n## Case study: Heights of adults\n\n.task[\nThe following histogram shows the distribution of heights of 507 physically active individuals (`openintro::bdims$hgt`). Do the heights of these individuals follow a normal distribution?\n]\n\n.panelset.sideways[\n.panel[.panel-name[Plot]\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=90%}\n:::\n:::\n\n]\n.panel[.panel-name[Vote]\n\n<iframe src=\"https://app.sli.do/event/rxg9buzy\" height=\"100%\" width=\"100%\" frameBorder=\"0\" style=\"min-height: 560px;\" title=\"Slido\"></iframe>\n\n]\n\n]\n\n---\n\n.task[\nWhich of the following is the plot of the real data? (Note: A different binwidth than the previous plot is used.)\n]\n\n.panelset.sideways[\n.panel[.panel-name[Plot]\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/generate-null-dist-1.png){fig-align='center' width=100%}\n:::\n:::\n\n]\n.panel[.panel-name[Vote]\n\n<iframe src=\"https://app.sli.do/event/rxg9buzy\" height=\"100%\" width=\"100%\" frameBorder=\"0\" style=\"min-height: 560px;\" title=\"Slido\"></iframe>\n\n]\n]\n\n---\n\n## Code: Generate null data with a specific distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20211029)\n\nbdims_permuted_lineup <- lineup(null_dist(\"hgt\", dist = \"normal\"), n = 10)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ndecrypt(\"clZx bKhK oL 3OHohoOL Bd\")\n```\n:::\n\n```{.r .cell-code}\nggplot(data = bdims_permuted_lineup, aes(x = hgt)) +\n  geom_histogram(binwidth = 4) +\n  facet_wrap(~ .sample, nrow = 2)\n```\n:::\n\n\n--\n\n\n::: {.cell hash='17-visual-inference_cache/revealjs/unnamed-chunk-18_0937d253f5ea009b491503817c358f7e'}\n\n```{.r .cell-code}\ndecrypt(\"sD0f gCdC En JP2EdEPn ZO\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in decrypt(\"sD0f gCdC En JP2EdEPn ZO\"): NAs introduced by coercion\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PO2j w939 4F SEm434EF  NA\"\n```\n:::\n:::\n\n\n---\n\n## Generating the null data with residuals from a model\n\n- `null_lm()` takes as input a model specification formula as defined by `lm()` and method for generating null residuals from the model\n\n- Three built in methods for different (and valid) methods to generate null data when fitting a linear model: \n  - `method = \"pboot\"`\n  - `method = \"boot\"`\n  - `method = \"rotate\"`\n\n- `null_lm()` returns a function which given the data generates a null dataset\n\n---\n\n## Case study: Black cherry trees\n\nData measures the diameter, height and volume of timber in 31 felled black cherry trees (`datasets::trees`)\n\n.panelset[\n.panel[.panel-name[Summary]\n.small[\n\n::: {.cell}\n\n```{.r .cell-code}\nskim(datasets::trees)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n── Data Summary ────────────────────────\n                           Values         \nName                       datasets::trees\nNumber of rows             31             \nNumber of columns          3              \n_______________________                   \nColumn type frequency:                    \n  numeric                  3              \n________________________                  \nGroup variables            None           \n\n── Variable type: numeric ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate mean    sd   p0  p25  p50  p75 p100 hist \n1 Girth                 0             1 13.2  3.14  8.3 11.0 12.9 15.2 20.6 ▃▇▃▅▁\n2 Height                0             1 76    6.37 63   72   76   80   87   ▃▃▆▇▃\n3 Volume                0             1 30.2 16.4  10.2 19.4 24.2 37.3 77   ▇▅▁▂▁\n```\n:::\n:::\n\n]\n]\n.panel[.panel-name[Plot]\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/unnamed-chunk-21-1.png){width=80%}\n:::\n:::\n\n]\n]\n\n---\n\n## Fit the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrees_fit <- lm(log(Volume) ~ log(Girth) + log(Height), \n                data = datasets::trees)\n\ntidy(trees_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    -6.63    0.800      -8.29 5.06e- 9\n2 log(Girth)      1.98    0.0750     26.4  2.42e-21\n3 log(Height)     1.12    0.204       5.46 7.81e- 6\n```\n:::\n:::\n\n\n---\n\n## Augment the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrees_aug <- as_tibble(datasets::trees) %>%\n  mutate(\n    .resid = residuals(trees_fit),\n    .fitted = fitted(trees_fit)\n  )\n\ntrees_aug\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 5\n   Girth Height Volume   .resid .fitted\n   <dbl>  <dbl>  <dbl>    <dbl>   <dbl>\n 1   8.3     70   10.3  0.0219     2.31\n 2   8.6     65   10.3  0.0343     2.30\n 3   8.8     63   10.2  0.0138     2.31\n 4  10.5     72   16.4 -0.0106     2.81\n 5  10.7     81   18.8 -0.0430     2.98\n 6  10.8     83   19.7 -0.0420     3.02\n 7  11       66   15.6 -0.0557     2.80\n 8  11       75   18.2 -0.0443     2.95\n 9  11.1     80   22.6  0.0822     3.04\n10  11.2     75   19.9  0.00926    2.98\n# ℹ 21 more rows\n```\n:::\n:::\n\n\n---\n\n## Test\n\n- Hypotheses:\n  - $H_0$: Errors are $NID(0, \\sigma^2)$\n  - $H_A$: Errors are not $NID(0, \\sigma^2)$\n\n--\n- Visual statistic: Residuals plot (residuals vs. fitted)\n\n--\n- Null distributions: Generate residuals from random draws from $N(0, \\hat{sigma}^2)$ using the **nullabor** package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmethod <- null_lm(log(Volume) ~ log(Girth) + log(Height),\n                  method = \"pboot\")\n```\n:::\n\n\n--\n- Compare the visual statistic from the data to the null distributions using a **lineup**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2020)\ntrees_lineup <- lineup(method, true = trees_aug, n = 10)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ndecrypt(\"clZx bKhK oL 3OHohoOL Bd\")\n```\n:::\n:::\n\n\n---\n\n## Lineup\n\n.task[\nWhich one is the real residuals plot?\n]\n\n.panelset.sideways[\n.panel[.panel-name[Plot]\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](17-visual-inference_files/figure-revealjs/trees-lineup-1.png){fig-align='center' width=90%}\n:::\n:::\n\n]\n.panel[.panel-name[Vote]\n\n<iframe src=\"https://app.sli.do/event/rxg9buzy\" height=\"100%\" width=\"100%\" frameBorder=\"0\" style=\"min-height: 560px;\" title=\"Slido\"></iframe>\n\n]\n\n.panel[.panel-name[Code]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(trees_lineup, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  facet_wrap(~.sample, nrow = 2) +\n  theme(\n    axis.text = element_blank(), # remove data context\n    axis.title = element_blank() # remove data context\n  )\n```\n:::\n\n\n]\n]\n\n---\n\n## Decrypt\n\n\n::: {.cell hash='17-visual-inference_cache/revealjs/unnamed-chunk-27_e0af3d4be8e184c0c786fee2ae468e34'}\n\n```{.r .cell-code}\ndecrypt(\"sD0f gCdC En JP2EdEPn ZO\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in decrypt(\"sD0f gCdC En JP2EdEPn ZO\"): NAs introduced by coercion\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"PO2j w939 4F SEm434EF  NA\"\n```\n:::\n:::\n\n\n---\n\nclass: middle, inverse\n\n# The visual inference test\n\n---\n\n## The visual inference test\n\n- Notation:\n  - $n$: number of independent participants\n  - $X$: number of participants who detect the data plot\n  - $x$: observed value of $X$\n  - $m$: number of plots\n  - $p$: the probability of selecting the data plot\n\n--\n- Hypotheses:\n  - $H_0: p = 1 / m$ - The probability of the data plot being selected is $1 / m$ (same as all other plots)\n  - $H_A: p > 1 / m$ - The probability of the data plot being selected is greater than $1 / m$\n\n--\n- Under $H_0, X \\sim B(n, 1/m)$. Then, visual inference p-value:\n\n$$ p(X \\ge x) = 1 - P(X \\le x - 1) = \\sum_{k = x}^n {n \\choose k} \\frac{(m - 1)^k}{m^n} $$\n\n- In R: $P(X \\le x)$ = `pbinom(x, n, p)`\n\n---\n\n## Calculating p-values\n\nWe did three lineup tests today, where \n- $x$ is the number of people who spotted the real data and \n- $n$ is the number of people voting\n\nLet's calculate the p-values\n\n- Spot the real `mtcars` (n = 20)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pbinom(4, 12, 1/20)\n```\n:::\n\n\n- Spot the real `bdims::hgt` (n = 10)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pbinom(0, 12, 1/10)\n```\n:::\n\n\n- Spot the real residuals of `trees` model (n = 10)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pbinom(0, 12, 1/20)\n```\n:::\n\n\n---\n\nclass: middle, inverse\n\n# Acknowledgements\n\n---\n\n## Acknowledgements\n\n- [Statistical inference for exploratory data analysis and model diagnostics](https://royalsocietypublishing.org/doi/10.1098/rsta.2009.0120) by Andreas Buja , Dianne Cook , Heike Hofmann , Michael Lawrence , Eun-Kyung Lee , Deborah F. Swayne, and Hadley Wickham\n- [Graphical Inference for Infovis](https://vita.had.co.nz/papers/inference-infovis.pdf) by Hadley Wickham, Dianne Cook, Heike Hofmann, and Andreas Buja\n- [Using computational tools to determine whether what is seen in the data can be assumed to apply more broadly](https://eda.numbat.space/lectures/lecture-11b#2) by Emi Tanaka\n- [Extending beyond the data, what can and cannot be inferred more generally, given the data collection](https://eda.numbat.space/lectures/lecture-12a#2) by Emi Tanaka\n- The [**nullabor**](http://dicook.github.io/nullabor/) package\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}